---
title: "R's `mlr` package <br> as common modeling interface"
subtitle: "And maybe some R/Python discussions <br> On Kaggle bike sharing and weather data"
author: "Ingo Nader"
date: "2 May 2019"
#output: html_document
output: 
  ioslides_presentation:
    css: styles-um.css
    logo: img/logo-um-154x127.png
    widescreen: true
    keep_md: true
    #smaller: true  ## only works without "---" slide breaks (use ##)
    slide_level: 2
## csl: plos-one.csl
## link-citations: true
## bibliography: references.yaml
## References: See 
## http://pandoc.org/MANUAL.html#citation-rendering
## https://github.com/jgm/pandoc-citeproc
##
## Comments and Instructions
##
## ## ------------------------------------------- ##
## ## Controlling presentation (best use chrome):
## ## ------------------------------------------- ##
    # 'f' enable fullscreen mode
    # 'w' toggle widescreen mode
    # 'o' enable overview mode
    # 'h' enable code highlight mode
    # 'p' show presenter notes
##
## ## ------------------------------------------- ##
## ## Images
## ## ------------------------------------------- ##
##
## Replace markdown images "![]()" with R's include_graphics()
## (in order for them to scale to slide width properly):
## Search:
## !\[\]\((.+)\)^
## Replace with:
## ```{r, eval = TRUE, echo = FALSE, out.width = "100%", fig.align = "left"}\nknitr::include_graphics("\1")\n```
##
##
## ## ------------------------------------------- ##
## ## Font size in slides, and other layout stuff
## ## ------------------------------------------- ##
##
## use {.smaller} after title for single slides
## use {.flexbox .vcenter} for centering of text
## 
## ## ------------------------------------------- ##
## ## color:
## ## ------------------------------------------- ##
##
##   <div class="red2"></div>
## or:
##   <font color="red"> </font>
##
## ## ------------------------------------------- ##
## ## two-column layout:
## ## ------------------------------------------- ##
## 
## <div></div><!-- ------------------------------- needed as is before cols - -->
## <div style="float: left; width: 48%;"><!-- ---- start of first column ---- -->
## Put col 1 markdown here
## </div><!-- ------------------------------------ end of first column ------ -->
## <div style="float: left; width: 4%"><br></div><!-- spacing column -------- -->
## <div style="float: left; width: 48%;"><!-- ---- start of second column --- --> 
## Put col 2 markdown here
## </div><!-- ------------------------------------ end of second column ----- -->
## <div style="clear: both"></div><!-- end cols for text over both cols below -->
##
## additionally, if one column needs to start higher (for right columns and 
## short slide titles, mostly):
## <div style="float: left; width: 30%; margin-top: -15%"><!-- ---- start of second column              --> 
## 
## other possibilities (not as good):
## * In slide title line, use:
##   ## title {.columns-2}
## * put md into this div:
##   <div class="columns-2">  </div>
##
---
[//]: # (
http://www.w3schools.com/css/css_font.asp
http://www.cssfontstack.com/Helvetica
)

<style>  <!-- put CSS here to test quickly -->
</style>

<script type="text/x-mathjax-config">  <!-- LaTeX formula config -->
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  "HTML-CSS": { 
      preferredFont: "Arial", 
      availableFonts: [],
      scale: 85
      // styles: {".MathJax": {color: "#CCCCCC"}} 
      }
});
</script>


```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
#knitr::opts_chunk$set(echo = FALSE, eval = TRUE)
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
options(width = 120)

library(reticulate) ## for python chunks

path_raw <- "/Users/ingonader/data-um-sync/training/coursera-work/python-for-data-science-edx/week-09-and-10-final-project"
path_dat <- file.path(path_raw, "data")
path_img <- file.path(path_raw, "presentation/img")
#load(file = file.path(path_dat, "kgl-mlr-trials_v001b_save-old.Rdata"))
```


## Background and Overview 

* Based on work for edX-Course [Python for Data Science](https://courses.edx.org/courses/course-v1:UCSanDiegoX+DSE200x+2T2017/course/)
* Course project: investigates **to what extent** and 
**how weather and time of day** influence **bike rentals** 
in a public bike sharing system in Montreal.

* Analysis in Python for edX course (data prep, some ML models, interpretation)
* Redone using some new cool stuff in the R ecosystem:
  * `mlr` package as a common interface for machine learning in R
  * `iml` package for model interpretation ([Pointed out by Andreas/Slack](https://www.inovex.de/blog/machine-learning-interpretability/))

**Note**: Only parts of each package can be covered here! No model interpretation due to time constraints (in preparing the presentation).

<p style="font-size: 16px; margin-top: 1%">
The full analysis is available in multiple python files on github:  [kgl-cycle-share-main-file.py](https://github.com/ingonader/python-for-data-science-edx/blob/master/week-09-and-10-final-project/kgl-cycle-share-main-file.py).
<br>
A synopsis is available as an ipython notebook [cycle-share-analysis-synopsis.ipynb](https://github.com/ingonader/python-for-data-science-edx/blob/master/week-09-and-10-final-project/cycle-share-analysis-synopsis.ipynb), or as [html](https://github.com/ingonader/python-for-data-science-edx/blob/master/week-09-and-10-final-project/cycle-share-analysis-synopsis.html) to download.
</p>


## Dataset(s) {.smaller}

<div></div><!-- ------------------------------- needed, but don't put anything here -->
<div style="float: left; width: 48%;"><!-- ---- start of first column               -->

Two datasets were used: **Bike sharing data**...

* **BIXI Montreal public bicycle sharing system**, North America's first 
  large-scale bike sharing system
* Available via Kaggle from<br> [https://www.kaggle.com/aubertsigouin/biximtl/home](https://www.kaggle.com/aubertsigouin/biximtl/home)
* For years $2014$ to $2017$
* Contains **individual records of bike trips**: timestamp and station code for 
  start and end of trip, duration
* $n = 14598961$ records (individual bike trips)
* Station codes, names, and position (latitude, longitude) 
  available in separate files, but only of secondary interest for this analysis

</div><!-- ------------------------------------ end of first column                 -->
<div style="float: left; width: 4%"><br></div><!-- spacing column -------- -->
<div style="float: left; width: 48%;"><!-- ---- start of second column              --> 

...and **weather data** from the Canadian government:

* Canadian governmentâ€™s past weather and climate service, available from<br> [http://climate.weather.gc.ca/ 
  historical_data/ <br> search_historic_data_e.html](http://climate.weather.gc.ca/historical_data/search_historic_data_e.html)
* API for **bulk data download**:<br> [http://climate.weather.gc.ca/climate_data/ <br> bulk_data_e.html](http://climate.weather.gc.ca/climate_data/bulk_data_e.html)
* Data can be downloaded per weather station per month and contains 
  **hourly measurements** of different metrics (e.g., timestamp, temperature, 
  relative humidity, atmospheric pressure, wind speed; different measures 
  available for different stations)
* $n = 35064$ hourly weather records in total (between $672$ and $744$ per monthly file)

</div><!-- ------------------------------------ end of second column                -->
<div style="clear: both"></div><!-- end floating section for text over both cols below -->


## Data Preparation and Cleaning {.smaller}

<div></div><!-- ------------------------------- needed as is before cols - -->
<div style="float: left; width: 48%;"><!-- ---- start of first column ---- -->

* First, **data download** was performed manually for the bike share data 
  from Kaggle (as only available after login), and via a Python script 
  for the weather data (bulk download).
* For the weather data, the **weather station** that was most central to the
  locations of the bike rides was picked (see data exploration).
* Next, the **data was loaded** and contatenated into a pandas `DataFrame` 
  each for individual bike rides and hourly weather data.
* The next step was **calculating the variable of interest: Hourly bike rides**. 
  This was done by aggregating individual bike trips to hourly counts of 
  trips (number of trips in each hour), using the starting time of the trip.
* Then, the **weather data was joined to the hourly bike ride data**, 
  using the common timestamp as join key.

</div><!-- ------------------------------------ end of first column ------ -->
<div style="float: left; width: 4%"><br></div><!-- spacing column -------- -->
<div style="float: left; width: 48%;"><!-- ---- start of second column --- --> 

* One feature **(wind chill) was dropped**, as it had too many 
  missing values ($77.9\%$ missing).
* Finally, **additional features were added** for the analysis: 
  hour of the day ($0$-$23$), day of the week ($0$-$6$, zero corresponding 
  to Monday, six corresponding to Sunday), month ($1$-$12$).
* These features, despite being categorical in nature, were kept as
  **continuous features**, as this proved to have more predictive
  power in the models.
* For modeling, **rows with missing values were dropped**, as the goal 
  is not having the most complete prediction coverage, but rather an 
  indication of the prediction quality that is possible with complete data. 
  In total, $1284$ rows ($0.04\%$) of the original data were dropped.
* The remaining rows were **split into training and testing set** ($90\%$ of the data, 
  $n = 26168$ rows for training, the remaining $10\%$, $n = 2908$ for testing).

</div><!-- ------------------------------------ end of second column ----- -->
<div style="clear: both"></div><!-- end cols for text over both cols below -->


## Research Question(s)

The research questions that I wanted to answer with my analysis were:

* **To what extent do** the number of 
  **bike rides depend on the current weather conditions**? That is, 
  how well can the number of bike rides 
  be predicted from weather data (and time of year, time of day)?
* What are the **most important factors** that influence the number 
  of bike rides?
* **How do these factors influence** the number of bike rides? What are 
  the main effects of these factors, and what are the interactions between
  them?


## Findings: Data Exploration

<div></div><!-- ------------------------------- needed, but don't put anything here -->
<div style="float: left; width: 53%"><!-- ---- start of first column               -->

* Context: **number of hourly bike trips** visualized for the time span between $2014$ and $2017$. 
* Baseline model: 
  * **Moving average**  (red line) 
  * $38.8\%$ variance explained $(r^2 = 0.388)$
  * Mean absolute error of $MAE = 316.2$

**Note**: 

* All data prep and exploration done in Python
* Data stored in `feather` format 
  (fast data exchange between R and Python)

</div><!-- ------------------------------------ end of first column                 -->

<div style="float: left; width: 2%"><br></div><!-- spacing column ----------------- -->
<div style="float: left; width: 45%; margin-top: -3%"><!-- ---- start of second column              --> 
```{r, eval = TRUE, echo = FALSE, out.width = "100%", fig.align = "left"}
knitr::include_graphics("img/expl-trips-per-hour-2014-2017.jpg")
```
<p style="font-size: 12px">
**Figure**: Number of hourly rides from $2014$ to $2017$. Each dot represents the 
number of trips in one specifc hour. Red line represents a 
moving average using a window of $14$ days.
<p>
</div><!-- ------------------------------------ end of second column                -->


## Methods

* $90\%$ training and $10\%$ test set 
* **Different machine learning models** (predicting hourly number of bike rides):
  * Random forest regression (`scikit-learn` / `randomForest`, `ranger`)
  * gradient boosting regression (`scikit-learn` / `gbm`)
  * gradient boosting regression via `xgboost` (Python and R)

* Hyperparameter tuning: randomized search with $4$-fold CV ($40$ iterations)
* Interpretation not part of this presentation  


## R package `mlr`: Overview

* **Standardized interface** for R's machine learning algorithms
* Infrastructure to:
  * **Resample** your models (cross validation, etc.)
  * **Select features**
  * Cope with **pre- and post-processing** of data 
  * **Optimize hyperparameters** (of models and also preprocessing)
  * **Compare models** in a statistically meaningful way
* Classification (including multilabel), regression, clustering, survival analysis
* Offers **parallelization** out of the box

**Note**: Only some parts of regression with hyperparameter tuning covered here.


## Building blocks

* **Task**: Data + meta data (target, positive class)
* **Learners**: Machine learning algorithms
  * `train()` $\rightarrow$ trained model: `predict()` , `performance()`, etc.
* **Resampling** strategy descriptions
  * `resample()` $\rightarrow$ trained model instances with performance metrics
* **Parameter tuners**: `tuneParams()` $\rightarrow$ trained and tuned model
* **Benchmark experiments** 
  * `benchmark()` $\rightarrow$ multiple trained models and their instances 
* **Wrappers** for Data preprocessing, Imputation, Over- and undersampling, Feature selection, Bagging, Parameter Tuning (return a **learner**)
* **Plots**


## Tasks

```{r, message=FALSE}
## load mlr package:
library(mlr)

## load housing data from package `mlbench`:
data(BostonHousing, package = "mlbench")

## define task
regr.task = makeRegrTask(id = "bh", 
                         data = BostonHousing, 
                         target = "medv")
regr.task

```

## Tasks

```{r, eval = FALSE}
## create a task: (= data + meta-information)
task_full <- makeRegrTask(id = "trip_cnt_mod", 
                     data = dat_hr_mod[varnames_model],
                     target = varnames_target)

task <- subsetTask(task = task_full, subset = idx_train)

task_small <- subsetTask(task = task_full, 
                         subset = sample(idx_test, size = 1000))

```

Cycling trip data example: 

* One full task (for final model estimation with evaluation on a fixed test set)
* Subtask for CV within the training set
* Subtask with small sample size for plotting


## Learners

```{r}
## Classification tree, set it up for predicting probabilities:
classif_lrn <- makeLearner("classif.randomForest", 
                           predict.type = "prob", 
                           fix.factors.prediction = TRUE)

## Regression gradient boosting machine, specify hyperparameters via a list
regr_lrn = makeLearner("regr.gbm", 
                       par.vals = list(
                         n.trees = 500, 
                         interaction.depth = 3)
                       )
```

* Parameters like `predict.type` are standardized for all learners
* Model-specific parameters passed in `par.vals` list

## Learners: Parameters

```{r}
## define learner without basic parameters:
learner_rf <- makeLearner("regr.randomForest", 
                          par.vals = list(ntree = 500))
getParamSet(learner_rf)  ## or: getParamSet("regr.randomForest")
```

## List of Learners

```{r}
## get list of learners:
listLearners(warn.missing.packages = FALSE)
```

## List of Learners with properties

```{r}
## get list of learners wich certain properties::
listLearners("regr", properties = c("missings", "weights"), warn.missing.packages = FALSE)
```

## Unified Interface

```{r, eval = FALSE}
## train learner:
model <- train(learner = learner_rf, task = task_full, subset = idx_train)
model
```
```
Model for learner.id=regr.randomForest; learner.class=regr.randomForest
Trained on: task.id = trip_cnt_mod; obs = 26168; features = 8
Hyperparameters: ntree=500
```
```{r, eval = FALSE}
## access model:
getLearnerModel(model) %>% class()
```
```
[1] "randomForest"
```
```{r, eval = FALSE}
getLearnerModel(model)
```
```
Call:
 randomForest(x = data[["data"]], y = data[["target"]], ntree = 500,     
              keep.inbag = if (is.null(keep.inbag)) TRUE else keep.inbag) 
               Type of random forest: regression
                     Number of trees: 500
No. of variables tried at each split: 2

          Mean of squared residuals: 41190.02
                    % Var explained: 90.01
```

## Unified Interface

```{r, eval = FALSE}
## predict with learner:
pred <- predict(model, newdata = dat_hr_mod, subset = idx_test)
pred
```
```
Prediction: 2908 observations
predict.type: response
threshold: 
time: 1.47
   truth  response
2      5  42.53462
6      5  30.70638
... (#rows: 2912, #cols: 2)
```

## Inspect Learner Predictions

<div></div><!-- ------------------------------- needed as is before cols - -->
<div style="float: left; width: 48%;"><!-- ---- start of first column ---- -->
```{r, eval = FALSE}
## inspect predictions on a small subset
set.seed(1548)
task_small_prelim <- subsetTask(
  task = task_full, 
  subset = sample(idx_test, size = 1000)
)

plotLearnerPrediction(
  learner_rf, task = task_small_prelim, 
  features = "temp"
)

plotLearnerPrediction(
  learner_rf,
  task = task_small_prelim, features = c("temp", "rel_hum")
)

```
</div><!-- ------------------------------------ end of first column ------ -->
<div style="float: left; width: 4%"><br></div><!-- spacing column -------- -->
<div style="float: left; width: 48%;"><!-- ---- start of second column --- -->
```{r, eval = TRUE, echo = FALSE, out.width = "100%", fig.align = "left"}
knitr::include_graphics("img/plot-learner-pred-1d.jpg")
```
```{r, eval = TRUE, echo = FALSE, out.width = "100%", fig.align = "left"}
knitr::include_graphics("img/plot-learner-pred-2d.jpg")
```
</div><!-- ------------------------------------ end of second column ----- -->
<div style="clear: both"></div><!-- end cols for text over both cols below -->





## Performance Measures

```{r, eval = FALSE}
## assess performance of learner:
performance(pred, measures = list(mse, mae, rsq))
```
```
        mse         mae         rsq 
42114.37355   110.04546     0.89036 
```

```{r}
## list of suitable measures for a task:
listMeasures()
```

## Cross Validation

```{r, eval = FALSE}
## set random seed, also valid for parallel execution:
set.seed(4271, "L'Ecuyer")

## choose resampling strategy for parameter tuning:
rdesc <- makeResampleDesc(predict = "both", 
                          method = "CV", iters = 4)

## not needed: estimating performance using resampling:
res <- resample(learner = "regr.ranger", task = task, 
                resampling = rdesc,
                measures = list(mse, mae, rsq))
```

```
Resampling: cross-validation
Measures:             mse.test   mae.test   rsq.test   
[Resample] iter 1:    113423.0606216188.7838823   0.7348283     
[Resample] iter 2:    65289.2298107164.0962026  0.8057397    
[Resample] iter 3:    109819.4070038195.5073898   0.7204328     
[Resample] iter 4:    102574.8995368195.6119237   0.7466122     

Aggregated Result: mse.test.mean=97776.6492433,mae.test.mean=185.9998496,rsq.test.mean=0.7519033
```

## Parallelism

<div></div><!-- ------------------------------- needed as is before cols - -->
<div style="float: left; width: 53%;"><!-- ---- start of first column ---- -->
Supported backends for parallelism:

* local multicore execution using `parallel`
* socket and MPI clusters using `snow`
* makeshift SSH-clusters using `BatchJobs`
* high performance computing clusters  
  (managed by a scheduler like SLURM, Torque/PBS, SGE or LSF) also using BatchJobs.
</div><!-- ------------------------------------ end of first column ------ -->

<div style="float: left; width: 4%"><br></div><!-- spacing column -------- -->
<div style="float: left; width: 43%;"><!-- ---- start of second column --- --> 
<!-- <td style="padding-top: 2px;">...</td> -->
```{r, eval = FALSE}
## enable parallel execution on a multicore machine: 
library(parallelMap)
parallelStartMulticore(cpus = n_cpus, 
                       level = "mlr.resample")
```

<br>
Parallelism can be set to different execution levels:

```{r, echo = FALSE, results = "hide"}
library(parallelMap)
```
```{r, eval = FALSE}
parallelGetRegisteredLevels()
```
```
mlr: mlr.benchmark, mlr.resample, mlr.selectFeatures, 
     mlr.tuneParams, mlr.ensemble
```

</div><!-- ------------------------------------ end of second column ----- -->
<div style="clear: both"></div><!-- end cols for text over both cols below -->


## Parameter tuning

<div></div><!-- ------------------------------- needed as is before cols - -->
<div style="float: left; width: 68%;"><!-- ---- start of first column ---- -->
```{r, eval = FALSE}
## tuning strategy for parameter tuning:
ctrl <- makeTuneControlRandom(maxit = 40)
tune_measures <- list(rmse, mae, rsq, timetrain, timepredict)

## tune standard random forest implementation:
tune_results_rf <- tuneParams(
  "regr.randomForest", 
  task = task, resampling = rdesc, measures = tune_measures, control = ctrl,
  par.set = makeParamSet(
    makeIntegerParam("mtry", lower = 2, upper = length(varnames_features)),
    makeIntegerParam("nodesize", lower = 10, upper = 50),
    makeIntegerParam("ntree", lower = 100, upper = 500)
  )
)
tune_results_rf
```
```
Tune result:
Op. pars: mtry=6; nodesize=10; ntree=445
rmse.test.rmse=182.8800473,mae.test.mean=96.1463276,rsq.test.mean=0.9188789,
timetrain.test.mean=168.3022500,timepredict.test.mean=0.5545000
```
</div><!-- ------------------------------------ end of first column ------ -->

<div style="float: left; width: 8%"><br></div><!-- spacing column -------- -->
<div style="float: left; width: 24%;"><!-- ---- start of second column --- --> 

```{r, eval = FALSE}
## access tuned parameters:
tune_results_rf$x
```
```
$mtry
[1] 6

$nodesize
[1] 10

$ntree
[1] 445
```
</div><!-- ------------------------------------ end of second column ----- -->
<div style="clear: both"></div><!-- end cols for text over both cols below -->




## Benchmark experiments

```{r, eval = FALSE}
lrns_tuned <- list(
  makeLearner("regr.randomForest",  par.vals = tune_results_rf$x),
  makeLearner("regr.ranger", par.vals = tune_results_ranger$x),
  makeLearner("regr.gbm", par.vals = tune_results_gbm$x),
  makeLearner("regr.xgboost", par.vals = tune_results_xgboost$x)
)

## set resampling strategy for benchmarking:
rdesc_bm <- makeResampleDesc(predict = "both", 
                             method = "RepCV", reps = 3, folds = 4)

## refit tuned models on complete training data:
bmr_train <- benchmark(
  lrns_tuned, task, rdesc_bm,
  measures = list(rmse, mae, rsq,
                  timetrain, timepredict)
)
bmr_train
```
```
       task.id         learner.id rmse.test.rmse mae.test.mean rsq.test.mean timetrain.test.mean timepredict.test.mean
1 trip_cnt_mod  regr.randomForest       185.6066      97.34310     0.9158034            39.06592             0.1747500
2 trip_cnt_mod        regr.ranger       182.8889      95.97002     0.9182493            27.85592             1.3381667
3 trip_cnt_mod           regr.gbm       183.7731      95.91192     0.9174738           105.31608             0.6764167
4 trip_cnt_mod regr.gbm.ntreeplus       171.5927      87.12461     0.9280451           729.68542             4.3349167
5 trip_cnt_mod       regr.xgboost       169.8597      96.49248     0.9294890            24.11000             1.1610833
```


## Visualizing benchmark experiments


```{r, eval = FALSE}
bmr_train
```
```
       task.id         learner.id rmse.test.rmse mae.test.mean rsq.test.mean timetrain.test.mean timepredict.test.mean
1 trip_cnt_mod  regr.randomForest       185.6066      97.34310     0.9158034            39.06592             0.1747500
2 trip_cnt_mod        regr.ranger       182.8889      95.97002     0.9182493            27.85592             1.3381667
3 trip_cnt_mod           regr.gbm       183.7731      95.91192     0.9174738           105.31608             0.6764167
4 trip_cnt_mod regr.gbm.ntreeplus       171.5927      87.12461     0.9280451           729.68542             4.3349167
5 trip_cnt_mod       regr.xgboost       169.8597      96.49248     0.9294890            24.11000             1.1610833
```

<div></div><!-- ------------------------------- needed as is before cols - -->
<div style="float: left; width: 28%;"><!-- ---- start of first column ---- -->
<br>
```{r, eval = FALSE}
plotBMRBoxplots(bmr_train, 
                measure = mae, 
                style = "violin") +
  aes(fill = learner.id) + 
  geom_point(alpha = .5)
```

</div><!-- ------------------------------------ end of first column ------ -->
<div style="float: left; width: 4%"><br></div><!-- spacing column -------- -->
<div style="float: left; width: 68%;"><!-- ---- start of second column --- --> 
```{r, eval = TRUE, echo = FALSE, out.width = "100%", fig.align = "left"}
knitr::include_graphics("img/plot-bmr-boxplot-mae.jpg")
```
</div><!-- ------------------------------------ end of second column ----- -->
<div style="clear: both"></div><!-- end cols for text over both cols below -->

## R and Python Results

<div></div><!-- ------------------------------- needed as is before cols - -->
<div style="float: left; width: 63%;"><!-- ---- start of first column ---- -->
<p style="margin-top: -4%">
|Model                                       | $MAE_{test}$|   $r^2_{test}$| tuning time      |
|:----------------------------               |------------:|--------------:|-----------------:|
|Gradient Boosting  (R/gbm) (ntree++)        |       $81.1$|        $0.936$|   $\sim 260$ min |
|Gradient Boosting (Python/sklearn)          |       $85.4$|        $0.941$|              (?) |
|Gradient Boosting  (R/XGBoost)              |       $85.8$|        $0.942$|    $\sim 14$ min |
|Gradient Boosting  (R/gbm) (re-tuned)       |       $89.7$|        $0.927$|    $\sim 36$ min |
|Random Forest (R/ranger)                    |       $90.0$|        $0.928$|    $\sim 11$ min |
|Random Forest (R/randomForest)              |       $91.9$|        $0.924$|    $\sim 33$ min |
|Gradient Boosting  (R/gbm) (LR low)         |      $101.8$|        $0.927$|     $\sim 8$ min |
|Random Forest (Python/sklearn)              |      $111.2$|        $0.894$|    $\sim 20$ min |
|Gradient Boosting (Python/XGBoost)          |      $155.3$|        $0.865$|      (no tuning) |
</p>
</div><!-- ------------------------------------ end of first column ------ -->
<div style="float: left; width: 4%"><br></div><!-- spacing column -------- -->
<div style="float: left; width: 43%;"><!-- ---- start of second column --- --> 
</div><!-- ------------------------------------ end of second column ----- -->
<div style="clear: both"></div><!-- end cols for text over both cols below -->

<div style="font-size: 18px; margin-top: 1%">
Notes:

* All models used 40 iterations of random search with 4-fold CV for tuning 
  (except *Gradient Boosting (Python/XGBoost)*, where no parameter tuning was performed)
* R models **were refitted** on complete training data with parameters from tuning and scored on the same test data set, except *Gradient Boosting  (R/gbm) (re-tuned)*
* Python models **used best model** from tuning and were refitted on the same data set
* R and Python train/test splits were not identical (different test sets for R and Python)

</div>

## Python Modeling Discussion

Using `patsy` design matrices for formula interface:

```{python, eval = FALSE}
## formula as text for patsy: without interactions
formula_txt = target + ' ~ ' + \
    ' + '.join(features) + ' - 1'
formula_txt
```
```
"Q('trip_cnt') ~ Q('Month') + Q('Temp (Â°C)') + Q('Rel Hum (%)') + Q('Wind Dir (10s deg)') + 
 Q('Wind Spd (km/h)') + Q('Stn Press (kPa)') + Q('hr_of_day') + Q('day_of_week') - 1"
```
```{python, eval = FALSE}
## create design matrices using patsy (could directly be used for modeling):
dat_y, dat_x = patsy.dmatrices(formula_txt, dat_hr_all, 
                               NA_action = 'drop',
                               return_type = 'dataframe')
```

## Python Modeling Discussion (cont'd)

Train/test split and data type issues:

```{python, eval = FALSE}
## Split the data into training/testing sets (using patsy/dmatrices):
dat_train_x, dat_test_x, dat_train_y, dat_test_y = train_test_split(
    dat_x, dat_y, test_size = 0.1, random_state = 142)

## convert y's to Series (to match data types between patsy and non-patsy data prep:)
dat_train_y = dat_train_y[target]
dat_test_y = dat_test_y[target]
```


## Python Modeling Discussion (cont'd)

```{python, eval = FALSE}
## Instantiate random forest estimator:
mod_gb = GradientBoostingRegressor(
  n_estimators = 100, random_state = 42,
  loss = 'ls', learning_rate = 0.1,
  max_depth = 20, 
  min_samples_split = 70,min_samples_leaf = 30
)
# specify parameters and distributions to sample from:
param_distributions = { 
    "n_estimators" : stats.randint(50, 201),
    "learning_rate" : [0.2, 0.1, 0.05],
    "max_depth" : stats.randint(4, 21),
    "min_samples_leaf" : stats.randint(30, 61)
}
mod_randsearch = RandomizedSearchCV(
    estimator = mod_gb,
    param_distributions = param_distributions,
    n_iter = 40,
    scoring = "r2",
    cv = 4,
    random_state = 7, n_jobs = -1
)
mod_randsearch.fit(dat_train_x, dat_train_y)

## get best model (estimator): 
mod_gb = mod_randsearch.best_estimator_
```



## Links

* https://mlr.mlr-org.com/: MLR Homepage
* https://arxiv.org/abs/1609.06146: MLR tutorial
* https://www.inovex.de/blog/machine-learning-interpretability: Blog post on ML interpretability using the `mlr` package



<!-- ## References {.columns-2 .tiny} -->
